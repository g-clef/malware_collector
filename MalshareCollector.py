import datetime
import os
from typing import Tuple
from urllib import parse

import requests

from malwaretl_stoq_transformer import transformer

from malware_collector import MalwareCollector


class MalshareCollector(MalwareCollector):
    # plan: hit https://malshare.com API daily, get the list of malware links, find
    # any that we haven't already
    # downloaded, pull those

    query_url = "https://malshare.com/api.php?"

    type_map = {"HTML": '.html',
                'ASCII': ".txt",
                "PE32": ".exe",
                "JAVA": ".jar",
                "data": ".bin",
                "Android": ".apk",
                }

    def __init__(self):
        super(MalshareCollector, self).__init__()
        self.base_path = self.configfile.get("Malshare", "path")
        self.path = self.base_path
        self.api_key = self.configfile.get("Malshare", "api_key", vars=os.environ)

    def get_list(self):
        args = {"action": "getlist",
                "api_key": self.api_key}
        full_url = self.query_url + parse.urlencode(args)
        try:
            response = requests.get(full_url)
            return response.json()
        except Exception:
            return []

    def get_malware(self, hash_val, path) -> Tuple[bool, str]:
        detail_args = {"api_key": self.api_key,
                       "action": "details",
                       "hash": hash_val}
        try:
            detail_response = requests.get(self.query_url + parse.urlencode(detail_args))
            details = detail_response.json()
        except Exception:
            return False, ""
        # have to drop HTML ones, since there are so many and I can't download more than 1000/day.
        if details['F_TYPE'] == "HTML":
            return False, ""
        if details['F_TYPE'] in self.type_map:
            suffix = self.type_map[details['F_TYPE']]
        else:
            suffix = ".unknown"
        sources = details['SOURCES']
        download_args = {"api_key": self.api_key,
                         "action": "getfile",
                         "hash": hash_val}
        full_url = self.query_url + parse.urlencode(download_args)
        try:
            response = requests.get(full_url, stream=True)
            with open(os.path.join(path, hash_val + suffix), "wb") as fileHandle:
                for chunk in response.iter_content(8192):
                    fileHandle.write(chunk)
            with open(os.path.join(path, hash_val + ".sources.txt"), "w") as fileHandle:
                fileHandle.write("\n".join(sources))
        except Exception:
            return False, ""
        print(f"retrieved {hash_val} to {path}")
        return True, path

    def get(self):
        last_24_hours = self.get_list()
        daydirname = self.make_day_directory()
        total_retrieved = list()
        for entry in last_24_hours:
            if 'sha256' not in entry:
                continue
            success, path = self.get_malware(entry['sha256'], daydirname)
            if success:
                total_retrieved.append(path)
            if len(total_retrieved) > 1000:
                # their api system says I'm limited to 1000/day
                break
        return total_retrieved


if __name__ == "__main__":
    print("starting downloads")
    share = MalshareCollector()
    files_downloaded = share.get()
    print("download complete, extracting features.")
    if files_downloaded:
        stoq, metadata = transformer.init_malshare(scan_mode=True)
        metadata.extra_data['collection_time'] = datetime.datetime.utcnow().isoformat()
        share.scan_downloaded_files(stoq, metadata, files_downloaded)
    print(f"completed. grabbed {len(files_downloaded)} new files")
