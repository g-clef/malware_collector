import os
from urllib import parse
import requests
from malware_collector import MalwareCollector


class MalshareCollector(MalwareCollector):
    # plan: hit https://malshare.com API daily, get the list of malware links, find
    # any that we haven't already
    # downloaded, pull those

    query_url = "https://malshare.com/api.php?"

    type_map = {"HTML": '.html',
                'ASCII': ".txt",
                "PE32": ".exe",
                "JAVA": ".jar",
                "data": ".bin",
                "Android": ".apk",
                }

    def __init__(self):
        super(MalshareCollector, self).__init__()
        self.base_path = self.configfile.get("Malshare", "path")
        self.api_key = self.configfile.get("Malshare", "api_key", vars=os.environ)

    def get_list(self):
        args = {"action": "getlist",
                "api_key": self.api_key}
        full_url = self.query_url + parse.urlencode(args)
        try:
            response = requests.get(full_url)
            return response.json()
        except Exception:
            return []

    def get_malware(self, hash_val, path):
        detail_args = {"api_key": self.api_key,
                       "action": "details",
                       "hash": hash_val}
        try:
            detail_response = requests.get(self.query_url + parse.urlencode(detail_args))
            details = detail_response.json()
        except Exception:
            return False
        # have to drop HTML ones, since there are so many and I can't download more than 1000/day.
        if details['F_TYPE'] == "HTML":
            return False
        if details['F_TYPE'] in self.type_map:
            suffix = self.type_map[details['F_TYPE']]
        else:
            suffix = ".unknown"
        sources = details['SOURCES']
        download_args = {"api_key": self.api_key,
                         "action": "getfile",
                         "hash": hash_val}
        full_url = self.query_url + parse.urlencode(download_args)
        try:
            response = requests.get(full_url, stream=True)
            with open(os.path.join(path, hash_val + suffix), "wb") as fileHandle:
                for chunk in response.iter_content(8192):
                    fileHandle.write(chunk)
            with open(os.path.join(path, hash_val + ".sources.txt"), "w") as fileHandle:
                fileHandle.write("\n".join(sources))
        except Exception:
            return False
        print(f"retrieved {hash_val} to {path}")
        return True

    def get(self):
        last_24_hours = self.get_list()
        total_received = 0
        daydirname = self.make_day_directory()
        for entry in last_24_hours:
            if 'sha256' not in entry:
                continue
            success = self.get_malware(entry['sha256'], daydirname)
            if success:
                total_received += 1
            if total_received > 1000:
                # their api system says I'm limited to 1000/day
                break


if __name__ == "__main__":
    share = MalshareCollector()
    share.get()
