import datetime
import logging
import os

from typing import List, Optional
from urllib.parse import urlparse

import requests

from bs4 import BeautifulSoup
from malwaretl_stoq_transformer import transformer

from malware_collector import MalwareCollector


logger = logging.getLogger("vxug collector")

class VXUGCollector(MalwareCollector):
    # collect malware from https://samples.vx-underground.org/samples/Blocks/

    base_url = "https://samples.vx-underground.org/samples/Blocks/"
    sub_urls = ["APT Collection/",
                "Argus Collection/",
                "Bazaar Collection/",
                "Virusshare Collection/"
    ]

    def __init__(self):
        super().__init__()
        self.path = os.environ.get("VXUG_PATH", "/RAID")

    def download_file(self, href, name, subdir) -> Optional[str]:
        if href.startswith("http"):
            download_url = href
        else:
            download_url = self.base_url + href
        target_dir = os.path.join(self.path, subdir)
        if not os.path.exists(target_dir):
            os.mkdir(target_dir)
        full_saved_path = os.path.join(target_dir, name)
        if not os.path.exists(full_saved_path):
            logger.info(f"downloading {name}")
            response = requests.get(download_url, stream=True, timeout=60)
            with open(full_saved_path, "wb") as fileHandle:
                for chunk in response.iter_content(chunk_size=8192):
                    fileHandle.write(chunk)
            return full_saved_path
        return None

    @staticmethod
    def should_download_link(href) -> bool:
        parsed_url = urlparse(href)
        if parsed_url.netloc.startswith("samples.vx-underground.org") and parsed_url.path.endswith(".7z"):
            return True
        return False

    def get(self) -> List[str]:
        downloaded_files = list()
        for sub_dir in self.sub_urls:
            list_url = self.base_url + sub_dir
            base_list = requests.get(list_url, timeout=60)
            soup = BeautifulSoup(base_list.content, features='html.parser')
            links = soup.find_all("a")
            for a in links:
                if "href" in a.attrs:
                    href = a.attrs['href']
                    name = a.text
                    if self.should_download_link(href):
                        final_path = self.download_file(href, name, sub_dir)
                        if final_path is not None:
                            downloaded_files.append(final_path)
        return downloaded_files


if __name__ == "__main__":
    logger.info("starting run")
    input_mode = transformer.InputMode.manual
    output_mode = transformer.OutputMode.silent
    stoq, metadata = transformer.init_vxug(input_mode=input_mode, output_mode=output_mode)
    stoq.log.disabled = True
    vxug = VXUGCollector()
    downloaded_files = vxug.run()
    logger.info(f"finished download, grabbed {len(downloaded_files)} files")
    if downloaded_files:
        metadata.extra_data['collection_time'] = datetime.datetime.utcnow().isoformat()
        vxug.scan_downloaded_files(stoq, metadata, downloaded_files)
    logger.info("done")