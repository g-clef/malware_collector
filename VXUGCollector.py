import os
import requests

from bs4 import BeautifulSoup

from malware_collector import MalwareCollector


class VXUGCollector(MalwareCollector):
    # collect malware from https://vxug.fakedoma.in/samples/

    base_url = "https://vxug.fakedoma.in"
    list_url = base_url + "/samples.html"

    def __init__(self):
        super().__init__()
        self.path = os.environ.get("VXUG_PATH", "/RAID")
        token = os.environ.get("VXUG_TOKEN", None)
        if token is not None:
            self.archive_token = token

    def download_file(self, href, name):
        download_url = self.base_url + href
        print(f"getting {name} from {download_url}")
        target_dir = os.path.join(self.path, name)
        if not os.path.exists(target_dir):
            os.mkdir(target_dir)
        full_saved_path = os.path.join(target_dir, name + ".7z")
        if not os.path.exists(full_saved_path):
            response = requests.get(download_url, stream=True)
            with open(full_saved_path, "wb") as fileHandle:
                for chunk in response.iter_content(chunk_size=8192):
                    fileHandle.write(chunk)
        return full_saved_path

    @staticmethod
    def should_download_link(a, href, name):
        if "href" not in a.attrs:
            return False
        if not href.startswith("/samples"):
            return False
        if not href.endswith(".7z"):
            return False
        if name.endswith(".txt"):
            return False
        return True

    def get(self):
        base_list = requests.get(self.list_url)
        soup = BeautifulSoup(base_list.content, features='html.parser')
        links = soup.find_all("a")
        for a in links:
            href = a.attrs['href']
            name = a.text
            if self.should_download_link(a, href, name):
                self.download_file(href, name)
                print(f"downloading {name}")


if __name__ == "__main__":
    vx = VXUGCollector()
    vx.run()
