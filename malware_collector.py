import git
import configparser
import zipfile
import os
import tempfile
import hashlib
from pathlib import Path
import shutil
import requests
from bs4 import BeautifulSoup
from urllib import parse


def make_hashes(filename):
    if os.path.isdir(filename):
        raise Exception("not a file")
    md5 = hashlib.md5()
    sha1 = hashlib.sha1()
    with open(filename, 'rb') as fileHandle:
        for chunk in iter(lambda: fileHandle.read(65536), b""):
            md5.update(chunk)
            sha1.update(chunk)
    return md5.hexdigest(), sha1.hexdigest()


class ZooCollector:
    # plan: git checkout https://github.com/ytisf/theZoo/tree/master/malwares/Binaries to the base path
    # then walk through each folder and unzip the files that contain the actual malware.
    #

    def __init__(self, base_path):
        self.base_path = base_path

    def get(self) -> bool:
        # run the git pull to get the most recent data out of the repository
        # note: this assumes that the repo is already set up.
        # returns a boolean of whether anything changed. True = something new is in the repo.
        repo = git.Repo(self.base_path)
        current = repo.head.commit
        repo.remotes.origin.pull()
        return current != repo.head.commit

    @staticmethod
    def _try_password_extract(zip_file, filename, destination, password) -> bool:
        try:
            zip_file.extract(filename, destination, pwd=password)
            return True
        except RuntimeError:
            # could mean this wasn't compressed with a password
            try:
                zip_file.extract(filename, destination)
                return True
            except Exception:
                pass
        return False

    def _handle_zipfile(self, target_zip: zipfile.ZipFile, password: bytes, destination_dir: str):
        contained_files = target_zip.namelist()
        for target in contained_files:
            if target.endswith(".txt"):
                continue
            elif target.startswith("."):
                continue
            elif target.endswith(".zip"):
                # nested zip files, ugh
                with tempfile.TemporaryDirectory() as tempdir:
                    success = self._try_password_extract(target_zip, target, tempdir, password)
                    if not success:
                        continue
                    sub_compressed_file = zipfile.ZipFile(os.path.join(tempdir, target), mode="r")
                    self._handle_zipfile(sub_compressed_file, password, destination_dir)
            else:
                with tempfile.TemporaryDirectory() as tempdir:
                    success = self._try_password_extract(target_zip, target, tempdir, password)
                    if not success:
                        continue
                    for file_name in os.listdir(tempdir):
                        full_path_to_target = os.path.join(tempdir, file_name)
                        try:
                            md5, sha1 = make_hashes(os.path.join(tempdir, file_name))
                        except Exception:
                            continue
                        final_name = md5 + "-" + sha1 + "-" + file_name
                        shutil.move(full_path_to_target, os.path.join(destination_dir, final_name))

    def analyze(self, malware_dir):
        # walk the base of the repo, find all the .zip files
        # unzip them using the password contained in the folder
        # delete the zip file once it's unzipped.
        full_path = os.path.join(self.base_path, "malwares", "Binaries")
        for target_dir in os.listdir(full_path):
            local_dir = os.path.join(full_path, target_dir)
            if os.path.exists(os.path.join(target_dir, "done.flag")):
                continue
            file_name = target_dir + ".pass"
            password_file = open(os.path.join(local_dir, file_name))
            password = password_file.read()
            password = password.encode('utf-8')
            malware_file = target_dir + ".zip"
            compressed_file = zipfile.ZipFile(os.path.join(local_dir, malware_file), mode="r")
            self._handle_zipfile(compressed_file, password, malware_dir)
            Path(os.path.join(local_dir, "done.flag")).touch()


class DasMalwerkCollector:
    # plan: hit https://dasmalwerk.eu daily, get the list of malware links, find any that we haven't already
    # downloaded, pull those.

    collection_url = "https://das-malwerk.herokuapp.com/"

    def __init__(self, base_path):
        self.base_path = base_path

    def _get_file(self, href, hash_name):
        response = requests.get(href)
        with open(os.path.join(self.base_path, hash_name + ".zip"), 'wb') as fileHandle:
            fileHandle.write(response.content)

    def get(self):
        already_done = set()
        completed_file_path = os.path.join(self.base_path, ".completed")
        if os.path.exists(completed_file_path):
            with open(completed_file_path) as fileHandle:
                for line in fileHandle:
                    line = line.strip()
                    already_done.add(line)
        response = requests.get(self.collection_url)
        soup = BeautifulSoup(response.content, features='html.parser')
        table = soup.table
        rows = table.find_all("tr")
        did_something = False
        for row in rows:
            elements = row.find_all("td")
            if len(elements) < 3:
                continue
            hash_val = elements[2].text.strip()
            if hash_val not in already_done:
                url = elements[1].a.attrs['href']
                self._get_file(url, hash_val)
                already_done.add(hash_val)
                did_something = True
        if did_something:
            with open(completed_file_path, "w") as fileHandle:
                for entry in already_done:
                    fileHandle.write("{}\n".format(entry))


class MalshareCollector:
    # plan: hit https://malshare.com API daily, get the list of malware links, find any that we haven't already
    # downloaded, pull those

    query_url = "https://malshare.com/api.php?"

    type_map = {"HTML": '.html',
                'ASCII': ".txt",
                "PE32": ".exe",
                "JAVA": ".jar",
                "data": ".bin",
                "Android": ".apk",
                }

    def __init__(self, base_path, api_key):
        self.base_path = base_path
        self.api_key = api_key

    def get_list(self):
        args = {"action": "getlist",
                "api_key": self.api_key}
        full_url = self.query_url + parse.urlencode(args)
        try:
            response = requests.get(full_url)
            return response.json()
        except Exception:
            return []

    def get_malware(self, hash_val):
        detail_args = {"api_key": self.api_key,
                       "action": "details",
                       "hash": hash_val}
        try:
            detail_response = requests.get(self.query_url + parse.urlencode(detail_args))
            details = detail_response.json()
        except Exception:
            return False
        # have to drop HTML ones, since there are so many and I can't download more than 1000/day.
        if details['F_TYPE'] == "HTML":
            return False
        if details['F_TYPE'] in self.type_map:
            suffix = self.type_map[details['F_TYPE']]
        else:
            suffix = ".unknown"
        sources = details['SOURCES']
        download_args = {"api_key": self.api_key,
                         "action": "getfile",
                         "hash": hash_val}
        full_url = self.query_url + parse.urlencode(download_args)
        try:
            response = requests.get(full_url)
            with open(os.path.join(self.base_path, hash_val + suffix), "wb") as fileHandle:
                fileHandle.write(response.content)
            with open(os.path.join(self.base_path, hash_val + ".sources.txt"), "w") as fileHandle:
                fileHandle.write("\n".join(sources))
        except Exception:
            return False
        return True

    def get(self):
        last_24_hours = self.get_list()
        total_received = 0
        for entry in last_24_hours:
            if 'sha256' not in entry:
                continue
            success = self.get_malware(entry['sha256'])
            if success:
                total_received += 1
            if total_received > 1000:
                # their api system says I'm limited to 1000/day
                break


class VXVaultCollector:
    # plan: hit http://vxvault.net/ViriList.php daily. Find the ones we don't already have, pull those
    pass


class MacMalwareCollector:
    # plan: hit https://macmalware.manwe.io/feed.json, get the list of recent malware, pull all the ones we haven't seen
    # yet.
    pass


class ObjectiveSeeCollector:
    # plan: hit https://objective-see.com/malware.json, walk it to find ones we don't already have yet, pull those
    pass


class AndroidMalwareGithubCollector:
    # plan: git sync https://github.com/ashishb/android-malware

    def __init__(self, base_path):
        self.base_path = base_path

    def get(self):
        # run the git pull to get the most recent data out of the repository
        # note: this assumes that the repo is already set up.
        # returns a boolean of whether anything changed. True = something new is in the repo.
        repo = git.Repo(self.base_path)
        current = repo.head.commit
        repo.remotes.origin.pull()
        return current != repo.head.commit


class URLHausCollector:
    # collect data and malware from https://urlhaus.abuse.ch/api/#retrieve
    pass


if __name__ == "__main__":
    configfile = configparser.ConfigParser()
    configfile.read("malware_collector.conf")
    zoo_path = configfile.get("theZoo", "git_path")
    android_malware_github_path = configfile.get("GithubAndroidMalware", "git_path")
    das_malwerk_path = configfile.get("DasMalwerk", "path")
    malshare_path = configfile.get("Malshare", "path")
    malshare_api_key = configfile.get("Malshare", "api_key")

    extracted_malware_path = configfile.get("Archive", "path")

    zooSync = ZooCollector(zoo_path)
    zooSync.get()

    androidSync = AndroidMalwareGithubCollector(android_malware_github_path)
    androidSync.get()

    dasMalwerkSync = DasMalwerkCollector(das_malwerk_path)
    dasMalwerkSync.get()

    malshare = MalshareCollector(malshare_path, malshare_api_key)
    malshare.get()